#!/usr/bin/env python

import sys, os

# first determine the top level directory (Ie. /path/to/ssscrape)
topdir = os.path.normpath(os.path.join(os.path.abspath(sys.argv[0]), os.pardir, os.pardir))

# then add the lib/ and lib/ext/ paths to sys.path
sys.path.insert(0, os.path.join(topdir, 'lib'))
sys.path.insert(0, os.path.join(topdir, 'lib', 'ext'))

import optparse
import MySQLdb
import _mysql_exceptions

from twisted.internet import reactor
from twisted.python import log

import ssscrapeapi
import ssscrapeapi.feeds

if __name__ == '__main__':

    # Handle command line options

    parser = optparse.OptionParser(usage="%prog -f feed_id -t task_id -u new_url")
    parser.add_option(
            '-f', '--feed',
            dest='feed_id', metavar='FEEDID', default=None,
            help="The feed id to modify.")
    parser.add_option(
            '-u', '--url',
            dest='url', metavar='URL', default=None,
            help="The new URL for the feed.")
    parser.add_option(
            '-t', '--task',
            dest='task_id', metavar='TASKID', default=None,
            help="The task to modify.")
    (options, args) = parser.parse_args()

    if not options.feed_id:
        parser.error('Please specify a feed id')

    if not options.url:
        parser.error('Please specify a new feed url')

    if not options.task_id:
        parser.error('Please specify a task id')

    # connect to the DB
    ssscrapeapi.database.connect()
    ssscrapeapi.database.connect('database')

    # load feed information
    feed = ssscrapeapi.feeds.Feed()
    feed.load(options.feed_id)
    old_url = feed['url']
    metadata = ssscrapeapi.feeds.FeedMetadata(feed_id=options.feed_id)
    id = metadata.find()
    metadata.load(id)

    # first, deal with metadata
    metadata2 = ssscrapeapi.feeds.FeedMetadata(options.url)
    id = metadata2.find()
    if id > 0:
        # if we have a metadata record f/t url, then load it -- we want to ue the correct one
        metadata2.load(id)
        metadata = metadata2
    else:
        metadata['url'] = options.url
        metadata.save()

    # now deal with the feed entry in the table
    if metadata['feed_id']:
        if feed['url'] != metadata['url']:
            feed['url'] = metadata['url']
            feed.save()

    # now address the task
    # load the task first
    task = ssscrapeapi.Task()
    task.load(options.task_id)

    # then deal with changing the program arguments
    task['args'] = "-u '%s'" % (ssscrapeapi.misc.quote_url(metadata['url']))

    # finally, change the resource id
    resource_name = ssscrapeapi.misc.url2resource(ssscrapeapi.misc.quote_url(metadata['url']))
    resource = ssscrapeapi.Resource() 
    resource['name'] = resource_name
    id = resource.find()
    if id <= 0:
        resource.save()
    task['resource_id'] = resource['id']

    # and save the (updated) task
    task.save()

    # disconnect from DB
    ssscrapeapi.database.disconnect('database')
    ssscrapeapi.database.disconnect()
