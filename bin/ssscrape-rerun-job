#!/usr/bin/env python

import sys, os

# first determine the top level directory (Ie. /path/to/ssscrape)
topdir = os.path.normpath(os.path.join(os.path.abspath(sys.argv[0]), os.pardir, os.pardir))

# then add the lib/ and lib/ext/ paths to sys.path
sys.path.insert(0, os.path.join(topdir, 'lib'))
sys.path.insert(0, os.path.join(topdir, 'lib', 'ext'))

import optparse
import MySQLdb
import _mysql_exceptions

from twisted.internet import reactor
from twisted.python import log

import ssscrapeapi
import ssscrapeapi.feeds

if __name__ == '__main__':

    # Handle command line options

    parser = optparse.OptionParser(usage="%prog -j job_id")
    parser.add_option(
            '-j', '--job',
            dest='job_id', metavar='JOBID', default=None,
            help="The job id to rerun.")
    parser.add_option(
            '-x', '--extra',
            dest='extra_args', metavar='ARGS', default='',
            help="Extra command line arguments to pass to the job's worker.")
    (options, args) = parser.parse_args()

    if not options.job_id:
        parser.error('Please specify a job id')

    # connect to the DB
    ssscrapeapi.database.connect()
    ssscrapeapi.database.connect('database')

    # first copy the job from the log table to the job table
    try:
        ssscrapeapi.database.execute('''INSERT INTO ssscrape_job SELECT * FROM ssscrape_job_log WHERE id = %s''', (options.job_id), 'database')
    except _mysql_exceptions.IntegrityError:
        pass

    # gather the info from the job we need
    cursor = ssscrapeapi.database.execute('''SELECT program, args, task_id FROM ssscrape_job WHERE id = %s''', (options.job_id), 'database')
    job = cursor.fetchone()

    # setup job env. variables
    job_env = {
        'SSSCRAPE_JOB_ID': options.job_id
    }
    if job[2]:
        job_env['SSSCRAPE_TASK_ID'] = job[2]

    # setup part of the command to export job and task environment variables
    env_str = ''
    for k in job_env:
        env_str = env_str + "export %s=%s &&" % (k, job_env[k]) 

    # find out the worker dir
    workers_dir = ssscrapeapi.config.get_string('manager', 'worker-directory')
    worker = os.path.join(workers_dir, job[0])
    
    # construct the command
    cmd = "%s %s %s %s" % (env_str, worker, job[1], options.extra_args)
    print >>sys.stderr, cmd.encode('utf-8', 'replace')

    # execute it
    ret = os.system(cmd.encode('utf-8', 'replace'))
    print >>sys.stderr, "Command exit code: ", ret

    # clean up
    try:
        ssscrapeapi.database.execute('''DELETE FROM `ssscrape_job_log` WHERE id = %s''', (options.job_id), 'database')
        ssscrapeapi.database.execute('''INSERT INTO `ssscrape_job_log` SELECT * FROM `ssscrape_job` WHERE id = %s''', (options.job_id), 'database')
        ssscrapeapi.database.execute('''DELETE FROM `ssscrape_job` WHERE id = %s''', (options.job_id), 'database')
    except _mysql_exceptions.IntegrityError:
        pass

    # disconnect from DB
    ssscrapeapi.database.disconnect('database')
    ssscrapeapi.database.disconnect()
