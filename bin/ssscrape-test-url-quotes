#!/usr/bin/env python

import sys, os

# first determine the top level directory (Ie. /path/to/ssscrape)
topdir = os.path.normpath(os.path.join(os.path.abspath(sys.argv[0]), os.pardir, os.pardir))

# then add the lib/ and lib/ext/ paths to sys.path
sys.path.insert(0, os.path.join(topdir, 'lib'))
sys.path.insert(0, os.path.join(topdir, 'lib', 'ext'))

import optparse
import MySQLdb
import _mysql_exceptions

from twisted.internet import reactor
from twisted.python import log

import ssscrapeapi
import ssscrapeapi.feeds
import peilend

if __name__ == '__main__':

    # connect to the DB
    ssscrapeapi.database.connect()
    ssscrapeapi.database.connect('database')

    # find all the empty articles in the timespan
    cursor = ssscrapeapi.database.execute('''SELECT guid FROM ssscrape_feed_item WHERE guid LIKE "http:%"''')
    for row in cursor.fetchall():
        qurl = ssscrapeapi.misc.quote_url(row[0])
        if row[0] != qurl:
            print "%s => %s" % (row[0], qurl)
    # disconnect from DB
    ssscrapeapi.database.disconnect('database')
    ssscrapeapi.database.disconnect()
